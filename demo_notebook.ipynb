{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osg.utils.general_utils import load_data, get_spatial_referents\n",
    "from osg.vlm_library import vlm_library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_fldr=f\"results/\"\n",
    "compression_strategy = \"position_direction\"                 #position_direction / direction / position\n",
    "data_format = \"robot\"                                        #robot/r3d\n",
    "data_path = \"../data/sample_robot_data\"                      #sample robotdata\n",
    "\n",
    "# data_format = \"r3d\"     \n",
    "# data_path = \"../data/sample_r3d_data/bdai_kitchen.r3d\"     #sample record3d data\n",
    "\n",
    "vlm_instance = vlm_library(vl_model=\"owl_vit\", data_src=data_format, seg_model= \"mobile_sam\", tmp_fldr=tmp_fldr) \n",
    "\n",
    "env_pointcloud, observations_graph = load_data(data_path,\n",
    "                                               data_format, \n",
    "                                               tmp_fldr, \n",
    "                                               pcd_downsample=False, \n",
    "                                               compression_percentage=80,\n",
    "                                               compression_technique=compression_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composible Referent Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Composible Referent ## Composible Referent Descriptor (CRD) \n",
    "    # CRDs are propositional expressions that represent specific referent instances by chaining comparators that encode descriptive spatial information. \n",
    "    # For more details see: https://arxiv.org/abs/2402.11498\n",
    "\n",
    "## CRD Syntax\n",
    "    # referent_1::isbetween(referent_2,referent_3)  :denotes that referent_1 is between referent_2 and referent_3.\n",
    "    # referent_1::isabove(referent_2)               :denotes that referent_1 is above referent_2.\n",
    "    # referent_1::isbelow(referent_2)               :denotes that referent_1 is below referent_2.\n",
    "    # referent_1::isleftof(referent_2)              :denotes that referent_1 is left of referent_2.\n",
    "    # referent_1::isrightof(referent_2)             :denotes that referent_1 is right of referent_2.\n",
    "    # referent_1::isnextto(referent_2)              :denotes that referent_1 is close to referent_2.\n",
    "    # referent_1::isinfrontof(referent_2)           :denotes that referent_1 is in front of referent_2.\n",
    "    # referent_1::isbehind(referent_2)              :denotes that referent_1 is behind referent_2.\n",
    "\n",
    "## Examples\n",
    "    # Desired referent:   table behind the fridge\n",
    "    # CRD representation: table::isbehind(fridge) \n",
    "\n",
    "    # Desired referent:    chair between the green laptop and the yellow box below the sofa\n",
    "    # CRD representation:  chair::isbetween(green_laptop,yellow_box::isbelow(sofa))\n",
    "\n",
    "    # Desired referent:    brown bag between the television and the kettle on the left of the green seat\n",
    "    # CRD representation:  brown_bag::isbetween(television, kettle::isleftof(green_seat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground referents and filter instances via spatial constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter comma seperated referent names or composible referent descriptors you wish to ground\n",
    "# referents_to_ground = [\"coffee_machine\", \"red_cup::isnextto(microwave)\"]\n",
    "\n",
    "referents_to_ground = [\"robot\", \"whiteboard::isinfrontof(green_plush_toy)\"]\n",
    "# referents_to_ground = [\"microwave\"]\n",
    "\n",
    "## Extract spatial information\n",
    "referent_spatial_details = get_spatial_referents(referents_to_ground)\n",
    "print(\"referent_spatial_details: \",referent_spatial_details,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial grounding\n",
    "relevant_element_details = vlm_instance.spatial_grounding(observations_graph, referent_spatial_details, visualize=True, use_segmentation=True, multiprocessing=True, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nReferents after spatial constraint filtering:\",len(relevant_element_details))\n",
    "#for all relevant elements print their ids\n",
    "print(f\"Filtered elements \\n\",[element['mask_id'] for element in relevant_element_details])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
