{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benedictquartey/opt/miniconda3/envs/osg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import open3d as o3d\n",
    "import more_itertools\n",
    "from torch import Tensor\n",
    "from typing import Iterator,NamedTuple\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from os import path, makedirs, listdir\n",
    "\n",
    "from osg.utils.dataset_class import PosedRGBDItem,R3DDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posed_rgbd_dataset(key: str,path: str) -> Dataset[PosedRGBDItem]:\n",
    "        return R3DDataset(path)\n",
    "\n",
    "def get_inv_intrinsics(intrinsics: Tensor) -> Tensor:\n",
    "    # return intrinsics.double().inverse().to(intrinsics)\n",
    "    fx, fy, ppx, ppy = intrinsics[..., 0, 0], intrinsics[..., 1, 1], intrinsics[..., 0, 2], intrinsics[..., 1, 2]\n",
    "    inv_intrinsics = torch.zeros_like(intrinsics)\n",
    "    inv_intrinsics[..., 0, 0] = 1.0 / fx\n",
    "    inv_intrinsics[..., 1, 1] = 1.0 / fy\n",
    "    inv_intrinsics[..., 0, 2] = -ppx / fx\n",
    "    inv_intrinsics[..., 1, 2] = -ppy / fy\n",
    "    inv_intrinsics[..., 2, 2] = 1.0\n",
    "    return inv_intrinsics\n",
    "\n",
    "def get_xyz(depth: Tensor, mask: Tensor, pose: Tensor, intrinsics: Tensor) -> Tensor:\n",
    "    \"\"\"Returns the XYZ coordinates for a set of points.\n",
    "\n",
    "    Args:\n",
    "        depth: The depth array, with shape (B, 1, H, W)\n",
    "        mask: The mask array, with shape (B, 1, H, W)\n",
    "        pose: The pose array, with shape (B, 4, 4)\n",
    "        intrinsics: The intrinsics array, with shape (B, 3, 3)\n",
    "\n",
    "    Returns:\n",
    "        The XYZ coordinates of the projected points, with shape (B, H, W, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    (bsz, _, height, width), device, dtype = depth.shape, depth.device, intrinsics.dtype\n",
    "\n",
    "    # Gets the pixel grid.\n",
    "    xs, ys = torch.meshgrid(\n",
    "        torch.arange(0, width, device=device, dtype=dtype),\n",
    "        torch.arange(0, height, device=device, dtype=dtype),\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "    xy = torch.stack([xs, ys], dim=-1).flatten(0, 1).unsqueeze(0).repeat_interleave(bsz, 0)\n",
    "    xyz = torch.cat((xy, torch.ones_like(xy[..., :1])), dim=-1)\n",
    "\n",
    "    # Applies intrinsics and extrinsics.\n",
    "    # xyz = xyz @ intrinsics.inverse().transpose(-1, -2)\n",
    "    xyz = xyz @ get_inv_intrinsics(intrinsics).transpose(-1, -2)\n",
    "    xyz = xyz * depth.flatten(1).unsqueeze(-1)\n",
    "    xyz = (xyz[..., None, :] * pose[..., None, :3, :3]).sum(dim=-1) + pose[..., None, :3, 3]\n",
    "\n",
    "    # Mask out bad depth points.\n",
    "    xyz = xyz.unflatten(1, (height, width))\n",
    "    xyz[mask.squeeze(1)] = 0.0  #lets do this at the data loading level\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def get_pointcloud(ds: Dataset[PosedRGBDItem], chunk_size: int = 16, threshold:float = 0.9, downsample=False) -> Iterator[tuple[Tensor, Tensor]]:\n",
    "    \"\"\"Iterates XYZ points from the dataset.\n",
    "\n",
    "    Args:\n",
    "        ds: The dataset to iterate points from\n",
    "        desc: TQDM bar description\n",
    "        chunk_size: Process this many frames from the dataset at a time\n",
    "\n",
    "    Yields:\n",
    "        The XYZ coordinates, with shape (B, H, W, 3), and a mask where a value\n",
    "        of True means that the XYZ coordinates should be ignored at that\n",
    "        point, with shape (B, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    #device = torch.device('cuda') if torch.cuda.is_available() else torch.deivce('cpu')\n",
    "    ds_len = len(ds)  # type: ignore\n",
    "    xyzs = []\n",
    "    rgbs = []\n",
    "\n",
    "    for inds in more_itertools.chunked(tqdm.trange(ds_len, desc='point cloud'), chunk_size):\n",
    "        rgb, depth, mask, pose, intrinsics = (\n",
    "            torch.stack(ts, dim=0)\n",
    "            for ts in zip(\n",
    "                #*((t.to(device) for t in (i.image, i.depth, i.mask, i.pose, i.intrinsics)) for i in (ds[i] for i in inds))\n",
    "                *((t for t in (i.image, i.depth, i.mask, i.pose, i.intrinsics)) for i in (ds[i] for i in inds))\n",
    "            )\n",
    "        )\n",
    "        rgb = rgb.permute(0, 2, 3, 1)\n",
    "        xyz = get_xyz(depth, mask, pose, intrinsics)\n",
    "        #mask = (~mask & (torch.rand(mask.shape, device=mask.device) > threshold))\n",
    "        mask = (~mask & (torch.rand(mask.shape) > threshold)) #depth reading confidence masking\n",
    "        rgb, xyz = rgb[mask.squeeze(1)], xyz[mask.squeeze(1)]\n",
    "        rgbs.append(rgb.detach().cpu())\n",
    "        xyzs.append(xyz.detach().cpu())\n",
    "    \n",
    "    xyzs = torch.vstack(xyzs)\n",
    "    rgbs = torch.vstack(rgbs)\n",
    "\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    merged_pcd.points = o3d.utility.Vector3dVector(xyzs)\n",
    "    merged_pcd.colors = o3d.utility.Vector3dVector(rgbs)\n",
    "    if downsample:\n",
    "        vl_size = 0.02\n",
    "        print(f\"Downsampling pointcloud || voxel_size: {vl_size}... \")\n",
    "        merged_pcd = merged_pcd.voxel_down_sample(voxel_size=vl_size)\n",
    "    else:\n",
    "         print(\"Skipped downsampling ... \")\n",
    "    return merged_pcd\n",
    "\n",
    "#function to generate random numeric alphanumeric string\n",
    "def random_string(string_length=20):\n",
    "    import random\n",
    "    import string\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(string_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading R3D file: 100%|██████████| 145/145 [00:02<00:00, 54.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# input_file = \"sample_data/sample.r3d\" \n",
    "input_file = \"../data/sample_r3d_data/bdai_kitchen.r3d\" \n",
    "output_file = \"r3dpointcloud.pcd\"\n",
    "posed_dataset = get_posed_rgbd_dataset(key=\"r3d\", path=input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "point cloud: 100%|██████████| 145/145 [00:00<00:00, 391.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped downsampling ... \n",
      "... pointcloud created \n"
     ]
    }
   ],
   "source": [
    "#test saving fused pointcloud\n",
    "env_pcd = get_pointcloud(posed_dataset, threshold=0.7, downsample=False)\n",
    "o3d.io.write_point_cloud(output_file, env_pcd)\n",
    "print(\"... pointcloud created \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample item\n",
    "index = 10\n",
    "sample_posedrgbd_item = posed_dataset.__getitem__(index)\n",
    "sample_image = sample_posedrgbd_item.image\n",
    "sample_depth = sample_posedrgbd_item.depth\n",
    "sample_mask = sample_posedrgbd_item.mask\n",
    "sample_intrinsics = sample_posedrgbd_item.intrinsics\n",
    "sample_pose = sample_posedrgbd_item.pose\n",
    "\n",
    "#plot image and dept map side by side\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(sample_image.permute(1, 2, 0))\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sample_depth.squeeze(0))\n",
    "plt.title(\"Depth Map\")\n",
    "#add confidence mask as subplot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(sample_mask.squeeze(0))\n",
    "plt.title(\"Confidence Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backprojecting single image\n",
    "\n",
    "# ds_len = len(ds)  # type: ignore\n",
    "xyzs = []\n",
    "rgbs = []\n",
    "res = [sample_posedrgbd_item]\n",
    "threshold = 0.9\n",
    "\n",
    "rgb, depth, mask, pose, intrinsics = sample_image, sample_depth, sample_mask, sample_pose, sample_intrinsics\n",
    "\n",
    "#expand dims to include batch size  \n",
    "rgb = rgb.unsqueeze(0)\n",
    "depth = depth.unsqueeze(0)\n",
    "mask = mask.unsqueeze(0)\n",
    "pose = pose.unsqueeze(0)\n",
    "\n",
    "print(rgb.shape)\n",
    "rgb = rgb.permute(0, 2, 3, 1)\n",
    "xyz = get_xyz(depth, mask, pose, intrinsics)\n",
    "\n",
    "\n",
    "\n",
    "# #mask = (~mask & (torch.rand(mask.shape, device=mask.device) > threshold))\n",
    "# mask = (~mask & (torch.rand(mask.shape) > 0))\n",
    "# print(\"before masking\", rgb.shape)\n",
    "# rgb, xyz = rgb[mask.squeeze(1)], xyz[mask.squeeze(1)]\n",
    "# print(\"after masking\", rgb.shape)\n",
    "# # rgb, xyz = rgb, xyz\n",
    "# rgbs.append(rgb.detach().cpu())\n",
    "# xyzs.append(xyz.detach().cpu())\n",
    "\n",
    "# xyzs = torch.vstack(xyzs)\n",
    "# rgbs = torch.vstack(rgbs)\n",
    "\n",
    "# merged_pcd = o3d.geometry.PointCloud()\n",
    "# merged_pcd.points = o3d.utility.Vector3dVector(xyzs)\n",
    "# merged_pcd.colors = o3d.utility.Vector3dVector(rgbs)\n",
    "# # merged_downpcd = merged_pcd.voxel_down_sample(voxel_size=0.03)\n",
    "# merged_downpcd = merged_pcd\n",
    "\n",
    "# #view point cloud\n",
    "# # o3d.visualization.draw_geometries([merged_downpcd])\n",
    "# o3d.io.write_point_cloud(\"single_rgbd.ply\", merged_downpcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
